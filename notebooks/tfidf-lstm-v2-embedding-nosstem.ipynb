{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, math\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import itertools\n",
    "\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, CuDNNGRU, Conv1D, CuDNNLSTM, Dense\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "#nltk model \n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "b67995f2cd04efbd86747fbca05dea1450f82e8b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "0e487c746161cdc8bfaf09a24dd1bb874afef115"
   },
   "outputs": [],
   "source": [
    "#pd.set_option('display.height', 1000)\n",
    "#pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "#pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "575ad3a0505f95215153b70f9dc84c2cd3c011fa"
   },
   "source": [
    "## 1.Explore dataframe features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "2aac670e30274b12dd31c8e06a5d403e45477baf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    qid                                      question_text  \\\n",
      "0  00002165364db923c7e6  How did Quebec nationalists see their province...   \n",
      "1  000032939017120e6e44  Do you have an adopted dog, how would you enco...   \n",
      "2  0000412ca6e4628ce2cf  Why does velocity affect time? Does velocity a...   \n",
      "3  000042bf85aa498cd78e  How did Otto von Guericke used the Magdeburg h...   \n",
      "4  0000455dfa3e01eae3af  Can I convert montra helicon D to a mountain b...   \n",
      "\n",
      "   target  \n",
      "0       0  \n",
      "1       0  \n",
      "2       0  \n",
      "3       0  \n",
      "4       0  \n",
      "                    qid                                      question_text\n",
      "0  00014894849d00ba98a9  My voice range is A2-C5. My chest voice goes u...\n",
      "1  000156468431f09b3cae           How much does a tutor earn in Bangalore?\n",
      "2  000227734433360e1aae  What are the best made pocket knives under $20...\n",
      "3  0005e06fbe3045bd2a92  Why would they add a hypothetical scenario tha...\n",
      "4  00068a0f7f41f50fc399   What is the dresscode for Techmahindra freshers?\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"../input/train.csv\")\n",
    "# 1. fill up the missing values\n",
    "test_df =pd.read_csv(\"../input/test.csv\")\n",
    "print(train_df.head())\n",
    "print(test_df.head())\n",
    "\n",
    "# 2. Are there overlaps between train and test? No\n",
    "print(pd.core.common.intersection(train_df['question_text'], test_df['question_text']).tolist())\n",
    "print(pd.core.common.intersection(train_df['qid'], test_df['qid']).tolist())\n",
    "\n",
    "#3 Some data features\n",
    "# print('train data',train_df.info())\n",
    "#print('test data',test_df.info())\n",
    "#Are there replicated rows? No\n",
    "#print(train_df.nunique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "eb524f082e35bb9a43c53a07950f8fd45639e67d"
   },
   "source": [
    "## 2. Feature extraction from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "f13631ca516d65b2d60c8aeee26b93464cfda542"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['what does   mean?', 'what is the difference between   and  ?', 'what are the ways to avoid unwanted sexual attractions?', 'how we can find happiness?', 'who is present health minister of india?', 'what does a woman do when she loves her boyfriend but he doesn t want to have sex? that s right! he doesn t want to have sex ']\n"
     ]
    }
   ],
   "source": [
    "#1. Preprocession: Lowercase, stemming, lemmarization, stopwords\n",
    "def standardize_text(df, question_field):\n",
    "    df[question_field] = df[question_field].str.replace(r\"http\\S+\", \"\")\n",
    "    df[question_field] = df[question_field].str.replace(r\"http\", \"\")\n",
    "    df[question_field] = df[question_field].str.replace(r\"@\\S+\", \"\")\n",
    "    df[question_field] = df[question_field].str.replace(r\"[^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]\", \" \")\n",
    "    df[question_field] = df[question_field].str.replace(r\"@\", \"at\")\n",
    "    df[question_field] = df[question_field].str.lower()\n",
    "    return df\n",
    "# 2. \n",
    "train_clean = train_df.copy(deep=True) # modification of the orginial df will not be affected \n",
    "test_clean = test_df.copy(deep=True)\n",
    "train_clean = standardize_text(train_clean, 'question_text')\n",
    "test_clean = standardize_text(test_clean, 'question_text')\n",
    "# 3. Are there overlaps between train and test question_text after preprocession? Yes\n",
    "print(pd.core.common.intersection(train_clean['question_text'], test_clean['question_text']).tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "9a70477a85aca0d9df05ac6a6bbc80467c374998"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2196017it [03:24, 10737.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2196016 word vectors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# embdedding setup\n",
    "# Source https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html\n",
    "embeddings_index = {}\n",
    "f = open('../input/embeddings/glove.840B.300d/glove.840B.300d.txt')\n",
    "for line in tqdm(f):\n",
    "    values = line.split(\" \")\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "8f4912b409bd07c66b9b32f99212ad771ba61a63"
   },
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(train_clean, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "dddcc226926e60d9eb674ef1c92734a4fa3058ab"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:00<00:00, 13259.73it/s]\n"
     ]
    }
   ],
   "source": [
    "# Convert values to embeddings\n",
    "def text_to_array(text):\n",
    "    empyt_emb = np.zeros(300)\n",
    "    text = text[:-1].split()[:30]\n",
    "    embeds = [embeddings_index.get(x, empyt_emb) for x in text]\n",
    "    embeds+= [empyt_emb] * (30 - len(embeds))\n",
    "    return np.array(embeds)\n",
    "\n",
    "# train_vects = [text_to_array(X_text) for X_text in tqdm(train_df[\"question_text\"])]\n",
    "val_vects = np.array([text_to_array(X_text) for X_text in tqdm(val_df[\"question_text\"][:3000])])\n",
    "val_y = np.array(val_df[\"target\"][:3000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "4f2311e86d07936b88f8820928cc9adca4633a1f"
   },
   "outputs": [],
   "source": [
    "# Data providers\n",
    "batch_size = 64\n",
    "\n",
    "def batch_gen(train_df):\n",
    "    n_batches = math.ceil(len(train_df) / batch_size)\n",
    "    while True: \n",
    "        train_df = train_df.sample(frac=1.)  # Shuffle the data.\n",
    "        for i in range(n_batches):\n",
    "            texts = train_df.iloc[i*batch_size:(i+1)*batch_size, 1]\n",
    "            text_arr = np.array([text_to_array(text) for text in texts])\n",
    "            yield text_arr, np.array(train_df[\"target\"][i*batch_size:(i+1)*batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "c06041b7ee5792058819c138cc63b825cfa189d3"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import CuDNNLSTM, Dense, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "ef50d94d338ef4e7e2309ce12c49e0fb3b811578"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Bidirectional(CuDNNLSTM(64, return_sequences=True),\n",
    "                        input_shape=(30, 300)))\n",
    "model.add(Bidirectional(CuDNNLSTM(64)))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "f344ba26a37fa4ac83f7f3104bee41bff5617f82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.1384 - acc: 0.9480 - val_loss: 0.1255 - val_acc: 0.9540\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.1239 - acc: 0.9502 - val_loss: 0.1201 - val_acc: 0.9537\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.1202 - acc: 0.9520 - val_loss: 0.1195 - val_acc: 0.9527\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.1170 - acc: 0.9543 - val_loss: 0.1178 - val_acc: 0.9533\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.1148 - acc: 0.9554 - val_loss: 0.1157 - val_acc: 0.9567\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.1122 - acc: 0.9565 - val_loss: 0.1156 - val_acc: 0.9563\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.1075 - acc: 0.9575 - val_loss: 0.1112 - val_acc: 0.9553\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.1054 - acc: 0.9574 - val_loss: 0.1126 - val_acc: 0.9570\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.1123 - acc: 0.9559 - val_loss: 0.1120 - val_acc: 0.9573\n",
      "Epoch 10/20\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.1107 - acc: 0.9567 - val_loss: 0.1096 - val_acc: 0.9543\n",
      "Epoch 11/20\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.1083 - acc: 0.9564 - val_loss: 0.1092 - val_acc: 0.9570\n",
      "Epoch 12/20\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.1076 - acc: 0.9574 - val_loss: 0.1086 - val_acc: 0.9580\n",
      "Epoch 13/20\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.1088 - acc: 0.9570 - val_loss: 0.1088 - val_acc: 0.9603\n",
      "Epoch 14/20\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.1078 - acc: 0.9572 - val_loss: 0.1063 - val_acc: 0.9593\n",
      "Epoch 15/20\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.1052 - acc: 0.9593 - val_loss: 0.1070 - val_acc: 0.9597\n",
      "Epoch 16/20\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.1063 - acc: 0.9583 - val_loss: 0.1071 - val_acc: 0.9583\n",
      "Epoch 17/20\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.1053 - acc: 0.9584 - val_loss: 0.1075 - val_acc: 0.9600\n",
      "Epoch 18/20\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.1030 - acc: 0.9597 - val_loss: 0.1032 - val_acc: 0.9607\n",
      "Epoch 19/20\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.1025 - acc: 0.9590 - val_loss: 0.1052 - val_acc: 0.9617\n",
      "Epoch 20/20\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.1008 - acc: 0.9606 - val_loss: 0.1071 - val_acc: 0.9593\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1221ef5c50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mg = batch_gen(train_df)\n",
    "model.fit_generator(mg, epochs=20,\n",
    "                    steps_per_epoch=1000,\n",
    "                    validation_data=(val_vects, val_y),\n",
    "                    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "d1c01b5a704854c36229996b3f894e5f9bfb9092"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "221it [00:23,  9.39it/s]\n"
     ]
    }
   ],
   "source": [
    "#prediction part\n",
    "batch_size = 256\n",
    "def batch_gen(test_df):\n",
    "    n_batches = math.ceil(len(test_df) / batch_size)\n",
    "    for i in range(n_batches):\n",
    "        texts = test_df.iloc[i*batch_size:(i+1)*batch_size, 1]\n",
    "        text_arr = np.array([text_to_array(text) for text in texts])\n",
    "        yield text_arr\n",
    "\n",
    "test_df = pd.read_csv(\"../input/test.csv\")\n",
    "\n",
    "all_preds = []\n",
    "for x in tqdm(batch_gen(test_df)):\n",
    "    all_preds.extend(model.predict(x).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "ba5fd8920241e54810f5d6bdbfd8b6f4bbf71da2"
   },
   "outputs": [],
   "source": [
    "y_te = (np.array(all_preds) > 0.5).astype(np.int)\n",
    "\n",
    "submit_df = pd.DataFrame({\"qid\": test_df[\"qid\"], \"prediction\": y_te})\n",
    "submit_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "cad4d9a7345aff3603e6a65f55b75625fd187d51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qid,prediction\r\n",
      "00014894849d00ba98a9,0\r\n",
      "000156468431f09b3cae,0\r\n",
      "000227734433360e1aae,0\r\n",
      "0005e06fbe3045bd2a92,0\r\n",
      "00068a0f7f41f50fc399,0\r\n",
      "000a2d30e3ffd70c070d,0\r\n",
      "000b67672ec9622ff761,0\r\n",
      "000b7fb1146d712c1105,0\r\n",
      "000d665a8ddc426a1907,0\r\n"
     ]
    }
   ],
   "source": [
    "!head submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "b8a016529af0d8ff2bcd7887ba20f5de110f81c1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
